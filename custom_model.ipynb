{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsPY7KFMNk-f",
        "outputId": "2ca8a550-1dfb-4a7f-eb9d-d4a3626091ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK1Czh0F9TOt",
        "outputId": "9b92aaf7-e442-4ce7-8f02-d1e05d93fcad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5094 images belonging to 34 classes.\n",
            "Found 680 images belonging to 34 classes.\n",
            "Found 1020 images belonging to 34 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2325s\u001b[0m 9s/step - accuracy: 0.0323 - loss: 3.5300 - val_accuracy: 0.0373 - val_loss: 3.5176\n",
            "Epoch 2/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2025s\u001b[0m 8s/step - accuracy: 0.0399 - loss: 3.4885 - val_accuracy: 0.0824 - val_loss: 3.3433\n",
            "Epoch 3/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2016s\u001b[0m 8s/step - accuracy: 0.0755 - loss: 3.3352 - val_accuracy: 0.0824 - val_loss: 3.2479\n",
            "Epoch 4/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2014s\u001b[0m 8s/step - accuracy: 0.0900 - loss: 3.2288 - val_accuracy: 0.1029 - val_loss: 3.1737\n",
            "Epoch 5/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2034s\u001b[0m 8s/step - accuracy: 0.1147 - loss: 3.1631 - val_accuracy: 0.1108 - val_loss: 3.1553\n",
            "Epoch 6/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2052s\u001b[0m 8s/step - accuracy: 0.1115 - loss: 3.1406 - val_accuracy: 0.1225 - val_loss: 3.1089\n",
            "Epoch 7/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2012s\u001b[0m 8s/step - accuracy: 0.1288 - loss: 3.0734 - val_accuracy: 0.1284 - val_loss: 3.0548\n",
            "Epoch 8/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2013s\u001b[0m 8s/step - accuracy: 0.1350 - loss: 3.0415 - val_accuracy: 0.1392 - val_loss: 3.0444\n",
            "Epoch 9/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2051s\u001b[0m 8s/step - accuracy: 0.1617 - loss: 2.9623 - val_accuracy: 0.1578 - val_loss: 2.9388\n",
            "Epoch 10/10\n",
            "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2031s\u001b[0m 8s/step - accuracy: 0.1753 - loss: 2.8973 - val_accuracy: 0.1794 - val_loss: 2.8674\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "\n",
        "\n",
        "import sklearn\n",
        "import tensorflow\n",
        "import json\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class CUSTOM_MODEL:\n",
        "    def __init__(self, train_data_path,test_data_path,validation_path):\n",
        "      try:\n",
        "        self.train_data_path = train_data_path\n",
        "        self.test_data_path=test_data_path\n",
        "        self.validation_path=validation_path\n",
        "        self.target_label = os.listdir(self.train_data_path)  # Get class labels from directory names\n",
        "      except Exception as e:\n",
        "        er_type,er_msg,line_no = sys.exc_info()\n",
        "        print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "    def ImageClassifier(self):\n",
        "\n",
        "      try:\n",
        "\n",
        "        self.training_data= ImageDataGenerator(rescale=1/255,\n",
        "                                                     shear_range=0.2,\n",
        "                                                     zoom_range=0.2,\n",
        "                                                     horizontal_flip=True)\n",
        "        self.testing_data=ImageDataGenerator(rescale=1/255)\n",
        "        self.validation_data=ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "        self.train_final_data = self.training_data.flow_from_directory(\n",
        "            self.train_data_path,\n",
        "            target_size=(256, 256),\n",
        "            classes=self.target_label,\n",
        "            class_mode='categorical',\n",
        "            batch_size=20\n",
        "        )\n",
        "        self.test_final_data = self.testing_data.flow_from_directory(self.test_data_path,\n",
        "                                                          classes = self.target_label,\n",
        "                                                          target_size=(256,256))\n",
        "\n",
        "        self.validation_data = self.validation_data.flow_from_directory(self.validation_path ,\n",
        "                                                                  classes = self.target_label,\n",
        "                                                                  target_size=(256,256))\n",
        "      except Exception as e:\n",
        "        er_type,er_msg,line_no = sys.exc_info()\n",
        "        print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "    def build_model(self):\n",
        "        # Build a CNN model\n",
        "      try:\n",
        "\n",
        "        self.model = Sequential()\n",
        "\n",
        "        # First convolutional and max pooling layers\n",
        "        self.model.add(Conv2D(128, kernel_size=(3,3), input_shape=(256, 256, 3), padding='same', activation='relu'))\n",
        "        self.model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "        # Second convolutional and max pooling layers\n",
        "        self.model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "        # Third convolutional and max pooling layers\n",
        "        self.model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "        # Fourth convolutional and max pooling layers\n",
        "        self.model.add(Conv2D(8, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.model.add(MaxPool2D(pool_size=(2,2)))\n",
        "        # Flattening layer\n",
        "        self.model.add(Flatten())\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.model.add(Dense(32, activation='relu'))  # Hidden layer 1\n",
        "        self.model.add(Dense(16, activation='relu'))  # Hidden layer 2\n",
        "\n",
        "        # Output layer\n",
        "        self.model.add(Dense(len(self.target_label), activation='softmax'))\n",
        "\n",
        "        # Compile the model\n",
        "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      except Exception as e:\n",
        "        er_type,er_msg,line_no = sys.exc_info()\n",
        "        print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "    def train_model(self):\n",
        "\n",
        "      try:\n",
        "        self.build_model()\n",
        "        self.ImageClassifier()\n",
        "        # Train the model\n",
        "        self.model.fit(self.train_final_data,\n",
        "                       validation_data=self.validation_data,\n",
        "                       epochs=10)\n",
        "\n",
        "        #Save the model\n",
        "\n",
        "        self.model.save(\"/content/drive/MyDrive/Internship/output_folders/CUSTOM_MODEL.keras\")\n",
        "\n",
        "      except Exception as e:\n",
        "        er_type,er_msg,line_no = sys.exc_info()\n",
        "        print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  try:\n",
        "    train_data_path = \"/content/drive/MyDrive/Internship/train\"\n",
        "    test_data_path='/content/drive/MyDrive/Internship/test'\n",
        "    validation_path='/content/drive/MyDrive/Internship/validation'\n",
        "\n",
        "    obj =CUSTOM_MODEL(train_data_path,test_data_path,validation_path)\n",
        "    obj.train_model()\n",
        "\n",
        "\n",
        "  except Exception as e:\n",
        "    er_type,er_msg,line_no=sys.exc_info()\n",
        "    print(f'Error in line no:{line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "N22-b7NKRo7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, model_path, test_data_path, output_file):\n",
        "        try:\n",
        "            self.model_path = model_path\n",
        "            self.test_data_path = test_data_path\n",
        "            self.output_file = os.path.join(output_file, \"model_metrics.json\")\n",
        "\n",
        "        except Exception as e:\n",
        "         er_type,er_msg,line_no = sys.exc_info()\n",
        "         print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            self.model = load_model(self.model_path)\n",
        "\n",
        "        except Exception as e:\n",
        "           er_type,er_msg,line_no = sys.exc_info()\n",
        "           print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "    def load_test_data(self):\n",
        "\n",
        "        try:\n",
        "            self.test_data = ImageDataGenerator(rescale=1/255)\n",
        "            self.test_data = self.test_data.flow_from_directory(\n",
        "                self.test_data_path,\n",
        "                target_size=(256, 256),\n",
        "                batch_size=20,\n",
        "                class_mode='categorical',\n",
        "                shuffle=False\n",
        "            )\n",
        "            self.class_names = np.array(list(self.test_data.class_indices.keys()))\n",
        "\n",
        "        except Exception as e:\n",
        "         er_type,er_msg,line_no = sys.exc_info()\n",
        "         print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        try:\n",
        "            y_true = np.array(self.test_data.classes)\n",
        "            y_pred_prob = self.model.predict(self.test_data)\n",
        "            y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "            conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "            metrics = {}\n",
        "            total_samples = conf_matrix.sum()\n",
        "            accuracy = (np.sum(np.diag(conf_matrix))) / total_samples\n",
        "            metrics[\"Overall_Accuracy\"] = round(accuracy, 4)\n",
        "\n",
        "            num_classes = len(self.class_names)\n",
        "            for i in range(num_classes):\n",
        "                TP = conf_matrix[i, i]\n",
        "                FP = np.sum(conf_matrix[:, i]) - TP\n",
        "                FN = np.sum(conf_matrix[i, :]) - TP\n",
        "                TN = total_samples - (TP + FP + FN + TP)\n",
        "\n",
        "                precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "                recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "                f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "                metrics[self.class_names[i]] = {\n",
        "                    \"TP\": int(TP),\n",
        "                    \"TN\": int(TN),\n",
        "                    \"FP\": int(FP),\n",
        "                    \"FN\": int(FN),\n",
        "                    \"Accuracy\": round((TP + TN) / (TP + TN + FP + FN), 4),\n",
        "                    \"Precision\": round(precision, 4),\n",
        "                    \"Recall\": round(recall, 4),\n",
        "                    \"F1-Score\": round(f1_score, 4)\n",
        "                }\n",
        "\n",
        "            return metrics\n",
        "        except Exception as e:\n",
        "         er_type,er_msg,line_no = sys.exc_info()\n",
        "         print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "    def save_metrics(self, metrics):\n",
        "        try:\n",
        "            with open(self.output_file, \"w\") as f:\n",
        "                json.dump(metrics, f, indent=4)\n",
        "\n",
        "        except Exception as e:\n",
        "         er_type,er_msg,line_no = sys.exc_info()\n",
        "         print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"/content/drive/MyDrive/Internship/output_folders/CUSTOM_MODEL.keras\"\n",
        "    test_data_path = \"/content/drive/MyDrive/Internship/test\"\n",
        "    output_file = \"/content/drive/MyDrive/Internship/output_folders\"\n",
        "\n",
        "    evaluator = ModelEvaluator(model_path, test_data_path, output_file)\n",
        "\n",
        "    try:\n",
        "        evaluator.load_model()\n",
        "        evaluator.load_test_data()\n",
        "        metrics = evaluator.evaluate_model()\n",
        "        evaluator.save_metrics(metrics)\n",
        "\n",
        "    except Exception as e:\n",
        "         er_type,er_msg,line_no = sys.exc_info()\n",
        "         print(f'Error in line no: {line_no.tb_lineno} and Error Message : {er_msg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qte2B8UUI5w",
        "outputId": "6dc7e580-ea05-4c1f-8b9f-00e08650fbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 680 images belonging to 34 classes.\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3w7xmf-Ncf_x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}